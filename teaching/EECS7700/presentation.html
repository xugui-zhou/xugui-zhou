<!DOCTYPE html>
<html>
<head>
    <title>EECS 7700  - Schedule</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" title="style1">
    <!-- <link rel="icon" type="image/ico" href="images/favicon.ico"> -->
    <!-- <link href='https://fonts.googleapis.com/css?family=Open+Sans:400' rel='stylesheet' type='text/css'> -->
</head>
<body>

    <ul id="nav">
	    <li><a href="index.html">Home</a></li>
	    <li><a href="schedule.html">Schedule</a></li>
	    <li><a style="color:#232C2D; background:#FFFFFF" href="presentation.html">Presentation</a></li>
	</ul>
    

    <div id="all">
        

        <div id="intro">
            <table width = "100%">
                <!-- <tr>
                    <td>
                        <p align="left" style="font-size:22px">
                            <b>EE/CSC 7700 - Fall 2024 Paper Presentations<br></b>
                        </p>
                        
                        
                    </td>
                </tr> -->

                <tr>
                    <td>
                        <p align="left" style="font-size:18px; background-color: lightblue;">
                            <b>Week 6: Anomaly/Intrution Detection<br></b>
                        </p>
                        <p>
                            <b>Reading tasks </b> <br>
                            
                            A hybrid methodology for anomaly detection in Cyberâ€“Physical Systems  <a href="https://www.sciencedirect.com/science/article/pii/S0925231223011918" target="_blank"> Link </a>]<br>
                            Cybersecurity Challenges in the Offshore Oil and Gas Industry: An Industrial Cyber-Physical Systems (ICPS) Perspective  <a href="https://dl.acm.org/doi/10.1145/3548691" target="_blank"> Link </a>]<br>
                            Self-Configurable Cyber-Physical Intrusion Detection for Smart Homes Using Reinforcement Learning  <a href="https://ieeexplore.ieee.org/abstract/document/9277640" target="_blank"> Link </a>]<br>
                        </p>
                        
                        <p align="left" style="font-size:18px; background-color: lightblue;">
                            <b>Week 5: Data<br></b>
                        </p>
                        <p>
                            <b>Reading tasks </b> <br>
                            
                            Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks [<a href="https://arxiv.org/abs/1704.01155" target="_blank"> Link </a>]<br>
                        </p>

                        <p>
                            <b>Blog Post 6: Feature Squeezing</b> <br>
                            
                            <summary>coming soon...</summary>
    
                            [<a href="./presentations/p6/blog.html" target="_blank">Read more ...</a>]<br>
                        </p>

                        
                        <p align="left" style="font-size:18px; background-color: lightblue;">
                            <b>Week 4: Safety Validation in CPS<br></b>
                        </p>
                        <p>
                            <b>Reading tasks </b> <br>
                            
                            A survey of algorithms for black-box safety validation of cyber-physical systems [<a href="https://arxiv.org/abs/2005.02979" target="_blank"> Link </a>]<br>
                            AI Psychiatry: Forensic Investigation of Deep Learning Networks in Memory Images [<a href="https://www.usenix.org/system/files/sec24summer-prepub-517-oygenblik.pdf" target="_blank"> Link </a>]<br>
                        </p>

                        <p>
                            <b>Blog Post 5: Black-Box Safety Validation </b> <br>
                            The presentation reviews methods for ensuring the safety of autonomous cyber-physical systems (CPS), such as self-driving cars and aircraft, by treating the system as a black box in simulation environments. It highlights three main tasks: falsification (finding failure-inducing disturbances), most-likely failure analysis, and failure probability estimation. The paper discusses optimization techniques, path planning (like rapidly-exploring random trees), reinforcement learning, and importance sampling as key methods for black-box safety validation, emphasizing the challenges of scaling these methods to large, complex systems. It also surveys tools used for safety validation in critical CPS applications, with a focus on scalability, adaptability, and efficiency in testing rare failures.r analysis.

    
                            [<a href="./presentations/p5/presentation-5.html" target="_blank">Read more ...</a>]<br>
                        </p>

                        <p>
                            <b>Blog Post 4: AI Psychiatry </b> <br>
                            This presentation explores the forensic analysis of deep learning models using a novel technique called AiP (AI Psychiatry). AiP is designed to recover machine learning models from memory images, which is critical for investigating models that have been compromised or attacked. This process is especially important for understanding models in production environments. AiP supports popular frameworks such as TensorFlow and PyTorch and has demonstrated 100% accuracy in recovering models from memory for further analysis.

    
                            [<a href="./presentations/p4/presentation4.html" target="_blank">Read more ...</a>]<br>
                        </p>


                        <p align="left" style="font-size:18px; background-color: lightblue;">
                            <b>Week 3: Machine Learning Applications<br></b>
                        </p>
                        <p>
                            <b>Reading tasks </b> <br>
                            
                            Deep Residual Learning for Image Recognition [<a href="https://arxiv.org/abs/1512.03385" target="_blank"> Link </a>]<br>
                            Attention Is All You Need [<a href="https://arxiv.org/abs/1706.03762" target="_blank"> Link </a>]<br>
                            Privacy Auditing with One (1) Training Run [<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/9a6f6e0d6781d1cb8689192408946d73-Paper-Conference.pdf" target="_blank"> Link </a>]<br>
                        </p>

                        <p>
                            <b>Blog Post 3: Privacy Auditing </b> <br>
                            The Presented paper "Privacy auditing with One Training Run" address the challenges presented by privacy auditing methods on machine learning models. Privacy auditing refers to the assessment of a model's vulnerability to privacy attacks such as the membership inference attacks tested for in this paper. In such attacks, an adversaries tries to infer if specific data points were used in training the model, which could amount to data and privacy breach. However, traditional methods for auditing require multiple training runs, which can be computationally expensive and sometimes infeasible. Hence, the authors propose a novel approach that only uses a single training run, which significantly improves the auditing time by orders of magnitude. The proposed method employs the use of  "canary" data points, that are iteratively tested for on the model, to estimate the likelihood of potential breaches. The paper presents that by optimizing the differential privacy parameters  such as Epsilon(Privacy loss) and Delta(Signal noise), the model aims to maintain a balance between privacy protection and accuracy. To validate the results, the authors used a wide ResNet model trained on CIFAR-10 dataset under both white-box and black-box settings, and showcased significant estimation capability in white-box testing. While this methods vastly improves privacy auditing, trade-offs are noted in privacy guarentees where tightness of the bounds was comparatively lower compared to other models.
    
                            [<a href="./presentations/p3/final.html" target="_blank">Read more ...</a>]<br>
                        </p>

                        <p>
                            <b>Blog Post 2: Transformer </b> <br>
                            This paper introduces a novel sequence transduction model architecture named the Transformer. 
                            This architecture is based solely on attention mechanisms, eliminating the need for recursion and convolution. 
                            The model addresses the limitations of sequence models that rely on recursive processes, which perform poorly in parallelization and computational efficiency for longer sequences.
                            The Transformer adopts an encoder-decoder structure, where the encoder consists of identical layers with multi-head self-attention and fully connected feed-forward networks, 
                            while the decoder mirrors this structure but adds a multi-head attention layer on the encoder's output; utilizing scaled dot-product attention and multi-head attention, 
                            the model computes the importance of key-value pairs based on queries and allows joint attention across different subspaces, 
                            with encoder-decoder attention enabling the decoder to focus on all input positions, 
                            self-attention improving contextual understanding by attending to all positions within layers, 
                            and positional encodings ensuring the model captures the order of tokens in a sequence.
                            [<a href="./presentations/p2/final.html" target="_blank">Read more ...</a>]<br>
                        </p>

                        <p>
                            <b>Blog Post 1: ResNet </b> <br>
                            As the number of layers of neural networks increases, the problems of overfitting, gradient vanishing, and gradient explosion often occur, so this article came into being. In this paper, the concept of deep residual networks (ResNets) is proposed. By introducing "shortcut connections," this study solves the problem of gradient vanishing in deep network training and has an important impact on the field of deep learning. The method of the paper explicitly redefines the network layers as learning residual functions relative to the inputs. By learning residuals, the network can be optimized more easily and can train deeper models more efficiently. Therefore, this method can help solve the performance degradation problem that may occur when the network layer increases. In addition, the article displays the experimental part. The model shows significant improvements in handling large-scale visual recognition tasks like ImageNet and CIFAR-10. The application of deep residual networks in major visual recognition competitions like ILSVRC and COCO 2015 further proves their power and wide applicability.
                            [<a href="./presentations/p1/final.html" target="_blank">Read more ...</a>]<br>
                        </p>
                        <!-- <p align="right" style="font-size:18px">
                         <a href="./presentations/p1/final.html" target="_blank"> Read more ... </a><br>
                        </p> -->
                        
                        
                    </td>
                </tr>

            </table>
        </div>
        <br>
        <br>
    </div>


    <!-- <hr> -->
    </br>

  

</body>
</html>